# Lambda AI Environment â€” NVIDIA A10 (23GB) Instance
# Run from: ~/research-last/LAST/
# Data at:  ~/research-last/data/LAST-60-v2/data/processed_v2/xsub

environment:
  name: "lambda"
  type: "cloud"

paths:
  # train.py builds: {data_base}/LAST-60-v2/data/processed_v2/{split_type}/
  data_base:    "/lambda/nfs/research-last/data"
  data_root:    "/lambda/nfs/research-last/data/LAST-60-v2/data/processed_v2/xsub"
  output_root:  "/lambda/nfs/research-last/LAST-runs"
  checkpoints:  "/lambda/nfs/research-last/LAST-runs/checkpoints"
  logs:         "/lambda/nfs/research-last/LAST-runs/logs"

hardware:
  device:          "cuda"
  num_workers:     12       # 30 cores available; 12 keeps A10 fed, leaves room for OS
  pin_memory:      true
  prefetch_factor: 4        # Up from default 2; compensates for NFS read latency

lambda_ai:
  gpu:       "nvidia-a10"
  memory_gb: 23
  cpu_cores: 30
  ram_gb:    222
