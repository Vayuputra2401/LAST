# Kaggle Environment Configuration
# For running on Kaggle notebooks

environment:
  name: "kaggle" 
  type: "kaggle"
  
paths:
  # data_base: train.py builds path as {data_base}/LAST-60/data/processed/{split_type}
  # We symlink the actual Kaggle dataset to match this structure (see notebook setup below)
  data_base: "/tmp"
  
  # Raw data (V2 - MIB Preprocessed)
  data_root: "/kaggle/input/datasets/pathikreet/last-research-preprocessed-v2/xsub"
  
  # Output paths
  output_root: "/kaggle/working"
  checkpoints: "/kaggle/working/checkpoints"
  logs: "/kaggle/working/logs"
  
hardware:
  device: "cuda"
  num_workers: 2  # Kaggle has 2 CPU cores
  pin_memory: true
  
# Kaggle-specific constraints
kaggle:
  max_memory_gb: 13
  max_gpu_memory_gb: 16
  time_limit_hours: 9

# ── Notebook Setup (run this cell before training) ──
# train.py builds:  data_base/LAST-60/data/processed/{split_type}/
# So symlink the kaggle dataset xsub folder to match that structure:
#
# !mkdir -p /tmp/LAST-60/data/processed
# !ln -sf /kaggle/input/datasets/pathikreet/last-research-preprocessed-v2/xsub \
#          /tmp/LAST-60/data/processed/xsub
# !ls /tmp/LAST-60/data/processed/xsub   # verify: should list train_joint.npy etc.

